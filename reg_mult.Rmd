---
title: "Regressão Múltipla"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(rms)
library(plotly)
library(corrplot)
library(readxl)
```

## Load data

```{r echo=TRUE}
boston = readxl::read_excel("boston.xlsx")
b = boston#[,-1]
#b = b[-c(365),]
```


## Criar mapa de correlações

```{r echo=TRUE}
cor(b)->correlation
corrplot(correlation, method = "number")
```

## Criar mapa de correlações com valores logarítimicos

```{r echo=TRUE}
b_log = b
b_log[-c(14)] = log(b_log[-c(14)])
cor(b_log)->correlation
corrplot(correlation, method = "number")
```

## Manipulacao inicial dos dados
### Adicionando labels

```{r echo=TRUE}
b$chas=as.factor(b$chas)
levels(b$chas)=c("otherwise", "bounds river")
```

### Sumario dos dados 

```{r echo=TRUE}
summary(b)
```

### Filtrando dados

```{r echo=TRUE}
b = filter(b,medv <50)

#b$dis = ifelse(b$dis >= 3, 3, b$dis)
b$rad = ifelse(b$rad >= 9, 9, b$rad)
b$tax = ifelse(b$tax >= 500, 500, b$tax)
#b$nox = ifelse(b$nox >= 0.8, 0.75, b$nox)
#b$rm = ifelse(b$rm >= 7.5, 7.5, b$rm)
b$zn = ifelse(b$zn > 0, 1, 0)

#b = filter(b, id != 366)
```

### Ajustando valors


```{r echo=TRUE}
b = filter(b,medv <50)
```

### Transformando log

```{r echo=TRUE}
#b$crim = log(b$crim)
b$lstat = log(b$lstat)
b$dis = log(b$dis)
#b$medv = log(b$medv)
```

## Regressao incial
### Fazendo Regressão com todas as variaveis

```{r echo=TRUE}

reg.mlt=lm(data=b, medv ~ crim + zn + indus + chas + nox + rm + age + dis +
             rad + tax + ptratio + lstat)

summary(reg.mlt)

```

### Testando multicolinearidade
VIF > 5 indica alta chance de multicolinearidade.
```{r echo=TRUE}

round(vif(reg.mlt),1)

```


### Detecção de anomalias

Cooks Distances -> Pontos Influentes
Studentized residuals -> Outliers em Y
hat-values -> Outliers em X

```{r echo=TRUE}

influenceIndexPlot(reg.mlt , vars=c("Cook","Studentized","hat"))

```

## Regressao com seleção de variáveis

```{r echo=TRUE}

reg.mlt2=step(reg.mlt)

```

### Novo sumario da regressao

```{r echo=TRUE}

summary(reg.mlt2)

```

### Nova deteccao de multicolinearidade

```{r echo=TRUE}

round(vif(reg.mlt2),1)

```

### Novas anomalias

```{r echo=TRUE}

influenceIndexPlot(reg.mlt2 , vars=c("Cook","Studentized","hat"))

```

## Criar previsoes

```{r echo=TRUE}

b$medv_HAT=fitted.values(reg.mlt2) #Previsoes
b$RES=residuals(reg.mlt2) #Resuduais das previsoes
b$EP=b$RES/b$medv*100 #Erro percentual das previsoes

```

### Erro percentual

```{r echo=TRUE}

hist(b$EP, xlab = 'Erro Percentual (%)', main = '')

```

### Previsao e real

```{r echo=TRUE}


#plot(x = b$medv, y = b$medv_HAT, xlab = 'Preco Real', ylab = 'Previsao')

p = ggplot(b) +
  geom_point(aes(x = medv, y = medv_HAT, 
                 name = id #rownames(b)
                 )) +
  geom_smooth(method='lm',aes(x  = medv, y = medv) )
ggplotly(p)
```

### Teste anova

```{r echo=TRUE}

anova(reg.mlt2)

```


### Root mean sqared error

```{r echo=TRUE}

mean((b$medv - b$medv_HAT) ** 2) **0.5

```

## Fazer previsao

```{r echo=TRUE}
crim = 0.2651
zn = 0.0
indus = 9.69
chas = 0.0
nox = 0.5380
rm = 6.208
age = 77.50
dis = log(3.207)
rad = 5.0
tax = 330
ptratio = 19.05
lstat = log(11.36)

novo=data.frame(
  crim = crim,
  zn = zn,
  indus = indus,
  chas = chas,
  nox = nox,
  rm = rm,
  age = age,
  dis = dis,
  rad = rad,
  tax = tax,
  ptratio = ptratio,
  lstat = lstat
  )
lprice.hat=predict(reg.mlt2, novo)
lprice.hat

```
